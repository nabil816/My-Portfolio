{"cells":[{"cell_type":"markdown","source":["# **Importing the required files**"],"metadata":{"id":"d3TzHakduXDS"},"id":"d3TzHakduXDS"},{"cell_type":"code","source":["# Standard library imports\n","from os import listdir                    # To list files in a directory\n","from os.path import isfile, join         # To check if a path is a file and to join paths\n","import os                                # General OS-level operations\n","import datetime                          # For working with dates and times\n","\n","# Third-party library imports\n","from openpyxl import load_workbook       # To load and work with Excel .xlsx files\n","import pandas as pd                      # To handle tabular data and dataframes\n","import matplotlib.pyplot as plt          # To plot and visualize data\n","import numpy as np                       # To perform numerical operations\n","from google.colab import drive           # To access Google Drive in Google Colab environment\n","from datetime import datetime            # For working with dates and time\n","from dateutil.relativedelta import relativedelta # For working with dates and time\n"],"metadata":{"id":"ccSVnLs8uTJV","executionInfo":{"status":"ok","timestamp":1756637013340,"user_tz":-180,"elapsed":183,"user":{"displayName":"Nabil Ibrahim","userId":"15942015988695033533"}}},"id":"ccSVnLs8uTJV","execution_count":115,"outputs":[]},{"cell_type":"markdown","source":["# **Connecting Our Drive To Retrieve The Required Files**"],"metadata":{"id":"ovRLuiIxuiSW"},"id":"ovRLuiIxuiSW"},{"cell_type":"code","source":["# Mount your Google Drive into the Colab environment\n","drive.mount('/content/drive')\n","os.getcwd()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"LUy61IjwrRb0","executionInfo":{"status":"ok","timestamp":1756637015810,"user_tz":-180,"elapsed":2489,"user":{"displayName":"Nabil Ibrahim","userId":"15942015988695033533"}},"outputId":"76ce7c4e-d662-4ba7-b4c9-89772d0d846c"},"id":"LUy61IjwrRb0","execution_count":116,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"output_type":"execute_result","data":{"text/plain":["'/content/drive/My Drive/Stock Products'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":116}]},{"cell_type":"markdown","source":["# **Loading The Required File**"],"metadata":{"id":"zFkRIcb5vL20"},"id":"zFkRIcb5vL20"},{"cell_type":"code","execution_count":117,"id":"8c2a59a6-32ec-4a25-a2b4-f24d088c4c8a","metadata":{"id":"8c2a59a6-32ec-4a25-a2b4-f24d088c4c8a","executionInfo":{"status":"ok","timestamp":1756637021331,"user_tz":-180,"elapsed":5520,"user":{"displayName":"Nabil Ibrahim","userId":"15942015988695033533"}}},"outputs":[],"source":["# List of country codes corresponding to folder names\n","list_countries = [\"USA\", \"UK\", \"CA\", \"EU\", \"DE\", \"FR\", \"IT\", \"ES\", \"JP\"]\n","\n","# Initialize an empty DataFrame to collect all data\n","df = pd.DataFrame()\n","\n","# Loop through each country folder\n","for i in list_countries:\n","    try:\n","        # Define root path to the Stock Products folder for the current country\n","        root_path = r\"/content/drive/My Drive/Stock Products\"\n","        root_path = os.path.join(root_path, i)  # append country folder name\n","\n","        # Change working directory to the country folder\n","        os.chdir(root_path)\n","\n","        # Get a list of files in the current country folder\n","        onlyfiles = [\n","            f for f in listdir(root_path)\n","            if isfile(join(root_path, f))  # include only files, not directories\n","        ]\n","\n","        # Process each file in the folder\n","        for f in onlyfiles:\n","            # Read Excel file into a temporary DataFrame\n","            df_t = pd.read_excel(f)\n","\n","            # Add metadata columns: Country, Month, Year\n","            df_t['Country'] = i\n","            df_t['Month'] = str(f).strip().split()[0]  # assumes filename starts with month\n","            df_t['Year'] = str(f).strip().split()[1][:4]  # assumes year comes after month\n","\n","            # Clean column names: remove dashes and title-case them\n","            df_t.columns = (\n","                df_t.columns\n","                .str.replace('-', '', regex=False)\n","                .str.replace('â€“', '', regex=False)\n","                .str.title()\n","            )\n","\n","            # Concatenate the current DataFrame with the main one\n","            df = pd.concat([df_t, df], ignore_index=True)\n","\n","    except Exception:\n","        # Silently skip the country if an error occurs (e.g., folder missing, file corrupt)\n","        pass"]},{"cell_type":"markdown","source":[">> We now have the **df** DataFrame containing the Amazon Seller Central data."],"metadata":{"id":"AAoHhaY4vYfo"},"id":"AAoHhaY4vYfo"},{"cell_type":"code","source":["# ðŸ”· Define the root path to the folder where the file is stored\n","root_path = r'/content/drive/My Drive/Sales Data/Final Shape of Files'\n","\n","# ðŸ”· Change the working directory to the root path\n","os.chdir(root_path)\n","\n","# ðŸ”· Define the filename for the current price file\n","Current_price = 'Current_price'\n","\n","# ðŸ”· Read the current price data into a DataFrame\n","df_cp = pd.read_csv(Current_price)\n","\n","# ðŸ”· Sort by date descending and remove duplicate rows based on ASIN and Region\n","df_cp = df_cp.sort_values(by= 'Date', ascending = False).drop_duplicates(subset = ['ASIN', 'Region'])\n","\n","# ðŸ”· Rename the column 'Region' to 'Country' for consistency\n","df_cp.rename(columns = {'Region': 'Country'}, inplace = True)\n","\n","# ðŸ”· Replace specific country codes for better readability\n","df_cp['Country'].replace({'US':'USA', \"GB\": 'UK'}, inplace = True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RA4JZACupf_3","executionInfo":{"status":"ok","timestamp":1756637021371,"user_tz":-180,"elapsed":25,"user":{"displayName":"Nabil Ibrahim","userId":"15942015988695033533"}},"outputId":"70fd8168-f436-43a6-bc75-4c151e6692b2"},"id":"RA4JZACupf_3","execution_count":118,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3055462854.py:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n","The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n","\n","For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n","\n","\n","  df_cp['Country'].replace({'US':'USA', \"GB\": 'UK'}, inplace = True)\n"]}]},{"cell_type":"markdown","source":[">> We now have a DataFrame named **df_cp**, which holds the most recently detected price for each of our products."],"metadata":{"id":"qBgTcHYIqv_Y"},"id":"qBgTcHYIqv_Y"},{"cell_type":"code","source":["# ðŸ”· Define file name and columns to read\n","filname = 'Sales_full'\n","columns_to_read = ['SalesOrganic', 'SalesSponsoredProducts', 'SalesSponsoredDisplay', 'NetProfit', 'ASIN', 'Marketplace', 'Date']\n","\n","# ðŸ”· Load the data\n","df_s = pd.read_csv(filname, usecols = columns_to_read)\n","\n","# ðŸ”· Extract time-based features\n","df_s['Month'] = pd.to_datetime(df_s['Date'], format =\"%d/%m/%Y\").dt.month_name()\n","df_s['Year'] = pd.to_datetime(df_s['Date'], format =\"%d/%m/%Y\").dt.year\n","\n","# ðŸ”· Handle missing values\n","df_s.fillna(0, inplace = True)\n","\n","# ðŸ”· Calculate gross revenue\n","df_s['Gross Revenue'] = df_s['SalesOrganic'] +  df_s['SalesSponsoredProducts'] + df_s['SalesSponsoredDisplay']\n","\n","# ðŸ”· Define mapping dictionary\n","country_to_marketplace = {\n","    'Amazon.com':'US',\n","    'Amazon.ca':'CA' ,\n","    'Amazon.co.uk':'UK',\n","    'Amazon.de':'DE',\n","    'Amazon.fr':'FR',\n","    'Amazon.it':'IT',\n","    'Amazon.es':'ES',\n","    'amazon.co.jp':'JP',\n","    'amazon.com.mx':'MX'\n","}\n","\n","# ðŸ”· Map Marketplace to Country\n","df_s['Country'] = df_s['Marketplace'].replace(country_to_marketplace)\n","\n","# ðŸ”· Change the value of the \"US\" for consistency\n","df_s['Country'].replace({'US':'USA'}, inplace = True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ps-Z108Rp1qh","executionInfo":{"status":"ok","timestamp":1756637022874,"user_tz":-180,"elapsed":1500,"user":{"displayName":"Nabil Ibrahim","userId":"15942015988695033533"}},"outputId":"0ca9cfde-1491-43b3-b327-d3898da0451d"},"id":"Ps-Z108Rp1qh","execution_count":119,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1186359108.py:35: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n","The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n","\n","For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n","\n","\n","  df_s['Country'].replace({'US':'USA'}, inplace = True)\n"]}]},{"cell_type":"code","source":["# ðŸ”· Prompt user for choice\n","mont_of_last_30days = input(\"Do you want to get the margin of the last month or specific month \\nwrite the month like 'April'. Write anything else for the last 30 months for example n\\n\")\n","\n","# ðŸ”· Define list of month names\n","months = [\n","    \"January\", \"February\", \"March\", \"April\", \"May\", \"June\",\n","    \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"\n","]\n","\n","\n","# ðŸ”· Get current date\n","now = datetime.now()\n","\n","# ðŸ”· Calculate previous month\n","previous_month_date = now - relativedelta(months=1)\n","\n","# ðŸ”· Get previous month as number and name\n","previous_month_num = previous_month_date.month\n","previous_month_name = previous_month_date.strftime(\"%B\")\n","\n","# ðŸ”· Filter data based on user choice\n","# ðŸ”· If the user chooses a specific month, df_s will contain the margins for that month\n","if mont_of_last_30days.lower().capitalize() in months:\n","    df_s= pd.pivot_table(df_s,index=['Year','Month','Country', 'ASIN'], values=([ 'Gross Revenue', 'NetProfit']), aggfunc = 'sum').reset_index()\n","    df_s = df_s[df_s['Month'] == mont_of_last_30days]\n","\n","# ðŸ”· Otherwise, df_s will contain the margins for the previous month.\n","else:\n","    df_s= pd.pivot_table(df_s,index=['Year','Month','Country', 'ASIN'], values=([ 'Gross Revenue', 'NetProfit']), aggfunc = 'sum').reset_index()\n","    df_s = df_s[df_s['Month'] == previous_month_name]\n","\n","\n","# ðŸ”· Calculate Net Margin\n","df_s['Net Margin'] = df_s['NetProfit'] / df_s['Gross Revenue']\n","\n","# ðŸ”· Clean up the data\n","df_s.fillna(0, inplace = True)\n","df_s.replace([np.inf, -np.inf], 0, inplace=True)\n","numeric_columns = df_s.select_dtypes(include='float').columns\n","df_s[numeric_columns] = df_s[numeric_columns].round(2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g60s3ftqp6TK","executionInfo":{"status":"ok","timestamp":1756637030221,"user_tz":-180,"elapsed":7344,"user":{"displayName":"Nabil Ibrahim","userId":"15942015988695033533"}},"outputId":"f134093d-7636-426b-c56f-b23278b312bb"},"id":"g60s3ftqp6TK","execution_count":120,"outputs":[{"name":"stdout","output_type":"stream","text":["Do you want to get the margin of the last month or specific month \n","write the month like 'April'. Write anything else for the last 30 months for example n\n","n\n"]}]},{"cell_type":"markdown","source":[">> We now have the **df_s** DataFrame containing the margins of our products"],"metadata":{"id":"tSj2gtzAwluU"},"id":"tSj2gtzAwluU"},{"cell_type":"markdown","source":["# **The Cleaning Part**"],"metadata":{"id":"gUhxtqFXxFqF"},"id":"gUhxtqFXxFqF"},{"cell_type":"code","execution_count":121,"id":"5c2ffdc0-6c3c-404c-a634-4ca562a75fc6","metadata":{"id":"5c2ffdc0-6c3c-404c-a634-4ca562a75fc6","executionInfo":{"status":"ok","timestamp":1756637030281,"user_tz":-180,"elapsed":36,"user":{"displayName":"Nabil Ibrahim","userId":"15942015988695033533"}}},"outputs":[],"source":["# ðŸ“… Mapping of month names to their corresponding two-digit numbers\n","month_list = {\n","    'January':   '01',\n","    'February':  '02',\n","    'March':     '03',\n","    'April':     '04',\n","    'May':       '05',\n","    'June':      '06',\n","    'July':      '07',\n","    'August':    '08',\n","    'September': '09',\n","    'October':   '10',\n","    'November':  '11',\n","    'December':  '12'\n","}\n","\n","# ðŸ”· Replace month names in the 'Month' column with two-digit numeric month codes\n","df['Month_num'] = df['Month'].replace(month_list)\n","\n","# ðŸ”· Construct a date string column in the format DD-MM-YYYY (always using day '01').\n","# ðŸ”· We do this to ensure the data can be sorted by date, which will allow us to properly order the month columns in the report later.\n","df['Date'] = '01-' + df['Month_num'] + '-' + df['Year']\n","\n","# ðŸ”· Convert the 'Date' column to actual pandas datetime objects\n","df['Date'] = pd.to_datetime(df['Date'])\n","\n","# ðŸ”· Sort the DataFrame chronologically by the new 'Date' column\n","df.sort_values(by='Date', inplace=True)\n"]},{"cell_type":"code","execution_count":122,"id":"8721acae-222e-4fc3-9be8-eef88308aac2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8721acae-222e-4fc3-9be8-eef88308aac2","executionInfo":{"status":"ok","timestamp":1756637063043,"user_tz":-180,"elapsed":32729,"user":{"displayName":"Nabil Ibrahim","userId":"15942015988695033533"}},"outputId":"70fff646-16b2-4848-df82-45c693215ef3"},"outputs":[{"name":"stdout","output_type":"stream","text":["['USA', 'UK', 'CA', 'EU', 'DE', 'FR', 'IT', 'ES', 'JP']\n","Enter the country you need: JP\n","['June' 'July' 'August' 'September' 'October' 'November' 'December'\n"," 'January' 'February' 'March' 'April' 'May']\n","Enter the month you need (The first of the three months): May\n"]}],"source":["# ðŸ”· Display the list of available countries to the user\n","print(list_countries)\n","\n","# ðŸ”· Prompt the user to enter the country the user need to get its RSR report\n","inp_country = input('Enter the country you need: ')\n","\n","# ðŸ”· Show the list of unique months available in the dataset\n","print(df['Month'].unique())\n","\n","# ðŸ”· Prompt the user to enter the month they are interested in\n","inp_month = input('Enter the month you need (The first of the three months): ')\n","\n","# ðŸ”· Filter both df, df_cp, and df_s DataFrames to include only rows for the selected country\n","df =df[df['Country'] == inp_country]\n","df_s =df_s[df_s['Country'] == inp_country]\n","df_cp =df_cp[df_cp['Country'] == inp_country]\n","\n","# ðŸ”· Make a copy of the full country-specific DataFrame for further use if needed\n","df_all = df.copy()\n","\n","# ðŸ”· Further filter df to include only rows for the selected month\n","df =df[df['Month'] == inp_month]\n","\n","# ðŸ”· Getting the current year\n","current_year = datetime.now().year\n","\n","\n","# ðŸ”· Filter df and df_s to include only data for the current year\n","df =df[df['Year'] == str(current_year)]\n","df_s =df_s[df_s['Year'] == current_year]\n"]},{"cell_type":"markdown","source":[">> At this point, both **df** and **df_all** contain only the data for the country selected by the user. **df** contains only the selected month, which we use as a reference to filter **df_all**, extracting the chosen month along with all subsequent months in chronological order. This ensures that **df_all** includes only the months needed for the analysis.\n"],"metadata":{"id":"Jm9Js-Ud5ey4"},"id":"Jm9Js-Ud5ey4"},{"cell_type":"markdown","source":[">> We also have **df_c** and **df_s**, which contain the prices and margins"],"metadata":{"id":"mmCu7Yv7ubhY"},"id":"mmCu7Yv7ubhY"},{"cell_type":"code","execution_count":123,"id":"99fe1b30-5b62-4be5-bed8-274b728e09ca","metadata":{"id":"99fe1b30-5b62-4be5-bed8-274b728e09ca","executionInfo":{"status":"ok","timestamp":1756637063114,"user_tz":-180,"elapsed":44,"user":{"displayName":"Nabil Ibrahim","userId":"15942015988695033533"}}},"outputs":[],"source":["# ðŸ”· Filter `df_all` to include only rows where the date is on or after the first date in the filtered `df`\n","# (i.e., keep data starting from the selected month and onward)\n","df_all = df_all[df_all['Date'] >= str(df['Date'].unique()[0].date())]\n","\n","# ðŸ”· Extract the unique months present in the filtered `df_all`\n","list(df_all['Month'].unique())\n","\n","# ðŸ”· Store the list of months in `order_month` for later use\n","# ðŸ”· The order of the months is very important in the report, so we need to have a list of months sorted by their date. This makes us sure that the order of months columns will be correct\n","order_month = list(df_all['Month'].unique())"]},{"cell_type":"code","execution_count":124,"id":"16d49f7f-3619-46ec-892d-484cd0f96161","metadata":{"id":"16d49f7f-3619-46ec-892d-484cd0f96161","executionInfo":{"status":"ok","timestamp":1756637063159,"user_tz":-180,"elapsed":34,"user":{"displayName":"Nabil Ibrahim","userId":"15942015988695033533"}}},"outputs":[],"source":["# ðŸ”· Define the list of needed columns to keep from the original DataFrame\n","cols = [\n","    '(Child) Asin',\n","    'Session Percentage  Total',\n","    'Featured Offer (Buy Box) Percentage',\n","    'Units Ordered',\n","    'Unit Session Percentage',\n","    'Ordered Product Sales',\n","    'Month'\n","    ]\n","\n","# ðŸ”· Select only these columns from `df` and rename '(Child) Asin' â†’ 'ASIN'\n","df = df[cols].rename(columns = {'(Child) Asin': 'ASIN'})\n","\n","# ðŸ”· Create a pivot table on `df`, aggregating metrics by ASIN\n","# Metrics are summed across all months for each ASIN\n","df = (\n","    pd.pivot_table(\n","        df,\n","        index=['ASIN'],\n","        values=[\n","            'Session Percentage  Total',\n","            'Featured Offer (Buy Box) Percentage',\n","            'Units Ordered',\n","            'Unit Session Percentage',\n","            'Ordered Product Sales'\n","        ],\n","        aggfunc='sum'\n","    )\n","    .reset_index()\n",")\n","\n","\n","# ðŸ”· Prepare `df_all` in the same way, keeping all data (not just filtered to one month)\n","df_all = df_all[cols]\n","\n","# ðŸ”· Select only these columns from `df` and rename '(Child) Asin' â†’ 'ASIN'\n","df_all = df_all[cols].rename(columns = {'(Child) Asin': 'ASIN'})\n","\n","\n","# ðŸ”· Create a pivot table on `df_all`, aggregating metrics by ASIN and Month\n","df_all = (\n","    pd.pivot_table(\n","        df_all,\n","        index=['ASIN', 'Month'],\n","        values=[\n","            'Session Percentage  Total',\n","            'Featured Offer (Buy Box) Percentage',\n","            'Units Ordered',\n","            'Unit Session Percentage',\n","            'Ordered Product Sales'\n","        ],\n","        aggfunc='sum'\n","    )\n","    .reset_index()\n",")\n","\n","\n"]},{"cell_type":"markdown","source":[">> We have the ASINs of the products. Right now, we need to assign the names of this products based on the ASIN"],"metadata":{"id":"1EBEGMwlBfG5"},"id":"1EBEGMwlBfG5"},{"cell_type":"markdown","source":[">> We have a product list provided by Annies, titled â€œ*List of All Products - NEW*â€. **We will use this list to map ASINs to their corresponding product names.**"],"metadata":{"id":"mcyn-16bCFYF"},"id":"mcyn-16bCFYF"},{"cell_type":"code","execution_count":125,"metadata":{"id":"gB3ttcX-A4kb","executionInfo":{"status":"ok","timestamp":1756637063490,"user_tz":-180,"elapsed":313,"user":{"displayName":"Nabil Ibrahim","userId":"15942015988695033533"}}},"outputs":[],"source":["# ðŸ”· Define the root directory where the main product file is located\n","root_path = r\"/content/drive/My Drive/Stock Products\"\n","\n","# ðŸ”· Change the current working directory to the root path\n","os.chdir(root_path)\n","\n","# ðŸ”· Define the filename of the main Excel file\n","main_f = 'List of All Products - NEW.xlsx'\n","\n","# ðŸ”· The file contains multiple sheets, each listing products for a specific country. We only need the sheet for the country selected by the user.\n","# ðŸ”· Try to load the sheet corresponding to the selected country\n","try:\n","\n","    # Attempt to read the sheet named after the user-selected country\n","    df_main = pd.read_excel(main_f, sheet_name =inp_country )\n","\n","    # Drop unnecessary columns for analysis\n","    df_main.drop(columns = ['SKU', 'Product Name', 'Brand',\n","       'Product link', 'Listing Status', 'Remarks'], inplace = True)\n","\n","# ðŸ”· There isnâ€™t a separate sheet for each EU country, so we read the products from the â€˜EUâ€™ sheet instead of a specific country sheet.\n","# ðŸ”· Fallback: if the selected country sheet (country in the EU) is not found, default to 'EU' sheet\n","except:\n","\n","    # Attempt to read the EU sheet\n","    df_main = pd.read_excel(main_f, sheet_name ='EU' )\n","\n","    # Drop the same unnecessary columns\n","    df_main.drop(columns = ['SKU', 'Product Name', 'Brand',\n","       'Product link', 'Listing Status', 'Remarks'], inplace = True)"],"id":"gB3ttcX-A4kb"},{"cell_type":"markdown","source":[">>  We now have the **df_main** DataFrame, which contains both the ASINs and their corresponding product names."],"metadata":{"id":"vzUE4JNKGcnO"},"id":"vzUE4JNKGcnO"},{"cell_type":"code","execution_count":126,"id":"bcfcbaac-0f74-407e-87da-110b9fd34b51","metadata":{"id":"bcfcbaac-0f74-407e-87da-110b9fd34b51","executionInfo":{"status":"ok","timestamp":1756637063568,"user_tz":-180,"elapsed":67,"user":{"displayName":"Nabil Ibrahim","userId":"15942015988695033533"}}},"outputs":[],"source":["# ðŸ”· This report aims to track the performance of our top 60% of products, as the majority of our revenue comes from them.\n","# ðŸ”· Filter the DataFrame to keep only products whose 'Units Ordered' is above the 60th percentile (i.e., top 40% of products by units ordered)\n","df = df[df['Units Ordered'] > np.percentile(df['Units Ordered'], 60)].reset_index(drop = True)\n","\n","\n","# ðŸ”· Merge the filtered DataFrame (`df`) with the main product list (`df_main`)\n","# to bring in product names. Match on the 'ASIN' column.\n","# Keep only the first occurrence of each ASIN to avoid duplicates.\n","df = df.merge(df_main, how ='left', on = 'ASIN' ).drop_duplicates(subset = 'ASIN',keep = 'first')"]},{"cell_type":"code","execution_count":127,"id":"88886ef6-6a20-4467-b573-3c6876a5e3af","metadata":{"id":"88886ef6-6a20-4467-b573-3c6876a5e3af","executionInfo":{"status":"ok","timestamp":1756637063575,"user_tz":-180,"elapsed":66,"user":{"displayName":"Nabil Ibrahim","userId":"15942015988695033533"}}},"outputs":[],"source":["# ðŸ”· Keep only the relevant columns for the report\n","df = df[['Product Name (Other versions)','ASIN', 'Session Percentage  Total',\n","       'Featured Offer (Buy Box) Percentage', 'Units Ordered',\n","       'Unit Session Percentage', 'Ordered Product Sales']]\n","\n","# ðŸ”· Sort products by number of units ordered, in descending order, so the most important products appeared first\n","df.sort_values(by =  'Units Ordered', ascending  = False, inplace = True)"]},{"cell_type":"markdown","source":[">> Now we have **df**, which contains all the necessary information for our report. However, the report needs to be structured in a specific format: with two layers of columns â€” the first layer representing the months, and under each month, the ASIN and metric columns."],"metadata":{"id":"gVUy3MV4HB8k"},"id":"gVUy3MV4HB8k"},{"cell_type":"code","execution_count":128,"id":"f77f84d1-2321-47c7-bedb-5334b6737157","metadata":{"id":"f77f84d1-2321-47c7-bedb-5334b6737157","executionInfo":{"status":"ok","timestamp":1756637063582,"user_tz":-180,"elapsed":8,"user":{"displayName":"Nabil Ibrahim","userId":"15942015988695033533"}}},"outputs":[],"source":["# ðŸ”· Loop over each month in the desired order\n","for i in order_month:\n","\n","    # Filter `df_all` to include only rows for the current month\n","    df_t = df_all[df_all['Month'] == i]\n","\n","    # Select and order only the relevant columns for this month's data\n","    col = ['ASIN', 'Session Percentage  Total',\n","       'Featured Offer (Buy Box) Percentage', 'Units Ordered',\n","       'Unit Session Percentage', 'Ordered Product Sales']\n","    df_t = df_t[col]\n","\n","    # Rename columns by appending the current month to each metric column name\n","    col = list(df_t.columns[1:] + ' '+i)  # Add month suffix to metrics\n","    col.append('ASIN')                    # Keep ASIN as is\n","    col = [col[-1]] + col[:-1]            # Ensure ASIN stays as the first column\n","    df_t.columns = col                    # Rename Columns\n","\n","    # Merge this month's data into the main `df`, matching on ASIN\n","    df = df.merge(df_t, on = 'ASIN', how = 'left')"]},{"cell_type":"markdown","source":[">> Previously, we used **df** as a template to merge month-specific data from **df_all**. This caused the original columns from the selected month in df to become duplicated and retain unclear names, so we drop them to clean up the result."],"metadata":{"id":"Q7kqcpQbKoTX"},"id":"Q7kqcpQbKoTX"},{"cell_type":"code","execution_count":129,"id":"675a3d20-f195-444f-ba93-dd36e4678937","metadata":{"id":"675a3d20-f195-444f-ba93-dd36e4678937","executionInfo":{"status":"ok","timestamp":1756637063590,"user_tz":-180,"elapsed":2,"user":{"displayName":"Nabil Ibrahim","userId":"15942015988695033533"}}},"outputs":[],"source":["# ðŸ”· Define the list of junk columns that are not needed\n","cols = ['Session Percentage  Total',\n","       'Featured Offer (Buy Box) Percentage', 'Units Ordered',\n","       'Unit Session Percentage', 'Ordered Product Sales']\n","\n","# ðŸ”· Drop these metric columns from `df`\n","df.drop(columns = cols, inplace = True)\n","\n","# ðŸ”· Merge additional data (Net Margin and Price) from `df_s` into `df`, matching on ASIN\n","# If there are missing values after the merge, fill them with 'unavailable'\n","df = df.merge(df_s[['ASIN','Net Margin']], on ='ASIN', how = 'left').fillna('unavailable')\n","df = df.merge(df_cp[['ASIN','Price']], on ='ASIN', how = 'left').fillna('unavailable')"]},{"cell_type":"markdown","source":["# Save Our Report In The Stock Products Folder"],"metadata":{"id":"NVZuJhJcLxME"},"id":"NVZuJhJcLxME"},{"cell_type":"code","execution_count":130,"id":"0342adc6-6de2-4972-8b7a-64082fd5db9a","metadata":{"id":"0342adc6-6de2-4972-8b7a-64082fd5db9a","executionInfo":{"status":"ok","timestamp":1756637063607,"user_tz":-180,"elapsed":13,"user":{"displayName":"Nabil Ibrahim","userId":"15942015988695033533"}}},"outputs":[],"source":["# ðŸ”· Define the root directory where the output file will be saved\n","root_path = r\"/content/drive/My Drive/Stock Products\"\n","\n","# ðŸ”· Change the current working directory to the root path\n","os.chdir(os.path.join(root_path))\n","\n","# ðŸ”· Save the final `df` DataFrame to an Excel file\n","# The file is named using the selected month and country (e.g., \"January USA.xlsx\")\n","df.to_excel(inp_month + ' ' + inp_country+ '.xlsx')"]}],"metadata":{"kernelspec":{"display_name":"Python [conda env:base] *","language":"python","name":"conda-base-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}